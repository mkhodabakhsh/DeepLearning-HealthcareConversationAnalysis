{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sentence_types import load_encoded_data\n",
    "from sentence_types import encode_data, import_embedding\n",
    "from sentence_types import get_custom_test_comments\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Embedding\n",
    "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "from affirmation_function import affirmation_train_and_test\n",
    "from reflection_function  import reflection_train_and_test\n",
    "from calculate_probs_function import calc_probs_func\n",
    "from generate_html_ import generate_html_function\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C:\\Users\\Mohammad\\Desktop\\open_close_questions/models/2cnn\n",
      "Load Model? False\n",
      "Loading Data...\n",
      "170077 train sequences\n",
      "42520 test sequences\n",
      "107177 words\n",
      "4 classes\n",
      "Pad sequences (samples x time)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "Loading model!\n",
      "Loaded model from disk\n",
      "42520/42520 [==============================] - 83s 2ms/step\n",
      "Test accuracy: 0.9869238138198853\n",
      "\n",
      "Creating Manual Test...\n",
      "len(test_comments):  123\n",
      "len(test_comments_category):  123\n",
      "Encoding Data...\n",
      "Embedding Name C:\\Users\\Mohammad\\Desktop\\open_close_questions/data/default\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "123 train sequences\n",
      "0 test sequences\n",
      "123/123 [==============================] - 0s 2ms/step\n",
      "Manual test\n",
      "Test accuracy: 0.869918704032898\n"
     ]
    }
   ],
   "source": [
    "# User can load a different model if desired\n",
    "model_name      = \"C:\\\\Users\\Mohammad\\Desktop\\open_close_questions/models/2cnn\"\n",
    "embedding_name  = \"C:\\\\Users\\Mohammad\\Desktop\\open_close_questions/data/default\"\n",
    "load_model_flag = False\n",
    "arguments       = sys.argv[1:len(sys.argv)]\n",
    "if len(arguments) == 1:\n",
    "    model_name = arguments[0]\n",
    "    load_model_flag = os.path.isfile(model_name+\".json\")\n",
    "print(model_name)\n",
    "print(\"Load Model?\", (load_model_flag))\n",
    "\n",
    "# Model configuration\n",
    "maxlen = 300\n",
    "batch_size = 64\n",
    "embedding_dims = 75\n",
    "pool_size = 3\n",
    "stride = 1\n",
    "filters = 75\n",
    "kernel_size = 5\n",
    "epochs = 2\n",
    "# Add parts-of-speech to data\n",
    "pos_tags_flag = True\n",
    "\n",
    "\n",
    "#Export & load embeddings\n",
    "x_train, x_test, y_train, y_test = load_encoded_data(data_split=0.8, embedding_name=embedding_name,\n",
    "                                                     pos_tags=pos_tags_flag)\n",
    "#print(\"x_test::\",x_test)\n",
    "word_encoding, category_encoding = import_embedding(embedding_name)\n",
    "max_words   = len(word_encoding) + 1\n",
    "num_classes = np.max(y_train) + 1\n",
    "print(max_words, 'words')\n",
    "print(num_classes, 'classes')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('Convert class vector to binary class matrix (for use with categorical_crossentropy)')\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "load_model_flag = True\n",
    "if not load_model_flag:\n",
    "    print('Constructing model!')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dims,\n",
    "                        input_length=maxlen))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(filters,\n",
    "                     kernel_size,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=stride))\n",
    "    model.add(MaxPooling1D(pool_size=pool_size))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Conv1D(filters//2,\n",
    "                     kernel_size//2 + 1,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "else:\n",
    "    print('Loading model!')\n",
    "    # load json and create model\n",
    "    json_file = open(model_name + '.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    model.load_weights(model_name + \".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    # evaluate loaded model on test data\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Test accuracy:', score[1])\n",
    "test_comments, test_comments_category = get_custom_test_comments()\n",
    "# 2: Statement (Declarative Sentence)    1: Question (Interrogative Sentence)\n",
    "# 0: Exclamation (Exclamatory Sentence)  3: Command (Imperative Sentence)\n",
    "\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "data = pd.read_csv(current_dir + '/sentence_list.csv') \n",
    "trans_otter = data[\"sentence\"].tolist()\n",
    "grnd_truth_oq,grnd_truth_cq = data[\"open_q\"],data[\"close_q\"]\n",
    "grnd_truth_aff,grnd_truth_ref = data[\"affirm\"],data[\"reflect\"]\n",
    "\n",
    "Qlist_n = []\n",
    "Qstr_ = \"\"\n",
    "for t in range(len(trans_otter)): \n",
    "    Qlist_n.append(trans_otter[t].rstrip(\"\\n\"))\n",
    "    Qstr_ = Qstr_ + str(trans_otter[t])\n",
    "\n",
    "num_ = len(Qlist_n)\n",
    "test_comments , test_comments_category=[],[]\n",
    "test_comments = Qlist_n\n",
    "test_comments_category =  ['statement']*num_\n",
    "print(\"len(test_comments): \", len(test_comments))\n",
    "print(\"len(test_comments_category): \", len(test_comments_category))\n",
    "\n",
    "\n",
    "from termcolor import colored\n",
    "def write_red(f, str_):    f.write('<p style=\"color:#ff0000\">%s</p>' % str_)\n",
    "def write_black(f, str_):  f.write('<p style=\"color:#000000\">%s</p>' % str_)\n",
    "\n",
    "real , test =[],[]\n",
    "x_test, _, y_test, _ = encode_data(test_comments, test_comments_category, data_split=1.0,\n",
    "                                   embedding_name=embedding_name, add_pos_tags_flag=pos_tags_flag)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print('Manual test')\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "# Show predictions\n",
    "predictions = model.predict(x_test, batch_size=batch_size, verbose=2)\n",
    "for i in range(0, len(predictions)):\n",
    "    real.append(y_test[i].argmax(axis=0))\n",
    "    test.append(predictions[i].argmax(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded data from file data/metadata.pkl.\n",
      "Loaded data from file embeddings/probabilistic_freq_2.pkl.\n",
      "Saved data to file data/sample_otter_data.pkl.\n",
      "Loaded data from file data/sample_otter_data.pkl.\n",
      "Loaded data from file data/val_data.pkl.\n",
      "123/123 [==============================] - 1s 5ms/step\n",
      "len(data_tr.index) 1653\n",
      "len(aug_data.index) 182\n",
      "len(data_tr_bal.index) 2199\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[[1314  157]\n",
      " [  88  640]]\n",
      "[[111  12]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.90      0.95       123\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.90       123\n",
      "   macro avg       0.50      0.45      0.47       123\n",
      "weighted avg       1.00      0.90      0.95       123\n",
      "\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "[[1310  166]\n",
      " [  80  656]]\n",
      "[[119   4]\n",
      " [  0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.98       123\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       123\n",
      "   macro avg       0.50      0.48      0.49       123\n",
      "weighted avg       1.00      0.97      0.98       123\n",
      "\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "index_list_blue range(0, 10) ['\\nHow close were you to her.', 'How comfortable are you can take continuing to take it.', 'What are the health concerns.', 'Well, how can I best support that for you.', '\\nYeah, what would you like to do about checking Can I, how can I help to simplify that someone have this.', '\\nYeah, what would you like to do about checking Can I, how can I help to simplify that someone have this.', '\\nWhat about this since you have to drive during the day.', 'How do you feel about taking the medication with dinner.', 'How about.', \"So yes, what's in, you know, our goal is to get your agency at least under eight.\"]\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "WH_Questoin_what\n",
      "index_list_blue range(0, 10) ['\\nHow close were you to her.', 'How comfortable are you can take continuing to take it.', 'What are the health concerns.', 'Well, how can I best support that for you.', '\\nYeah, what would you like to do about checking Can I, how can I help to simplify that someone have this.', '\\nYeah, what would you like to do about checking Can I, how can I help to simplify that someone have this.', '\\nWhat about this since you have to drive during the day.', 'How do you feel about taking the medication with dinner.', 'How about.', \"So yes, what's in, you know, our goal is to get your agency at least under eight.\"]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "calc_probs_func('C:\\\\Users\\Mohammad/Desktop/affirmation_reflection/sentence_list_plus_labels.csv')\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path_csv_test = current_dir + '/sentence_list_plus_labels_plus_probs.csv'\n",
    "\n",
    "\n",
    "out_aff = affirmation_train_and_test(path_csv_test)\n",
    "out_ref = reflection_train_and_test(path_csv_test)\n",
    "#print('out_aff',out_aff)\n",
    "index_aff,index_ref = out_aff[1],out_ref[1]\n",
    "\n",
    "print(index_aff)\n",
    "\n",
    "question_flag = test\n",
    "generate_html_function(test_comments,question_flag,grnd_truth_oq,grnd_truth_cq,grnd_truth_aff,grnd_truth_ref,index_aff,index_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}